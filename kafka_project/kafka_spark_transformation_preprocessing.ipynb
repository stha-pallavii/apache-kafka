{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10eba714",
   "metadata": {},
   "source": [
    "# Kafka Project - Data Pre-Processing and Transformation with Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7a2686f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "response = requests.get(\"https://api.tvmaze.com/shows\")\n",
    "print(response.status_code)\n",
    "\n",
    "# print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaea2605",
   "metadata": {},
   "source": [
    "## Pre-processing in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "899fb2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/18 16:57:22 WARN Utils: Your hostname, pallavi-xps resolves to a loopback address: 127.0.1.1; using 192.168.1.85 instead (on interface wlp2s0)\n",
      "22/11/18 16:57:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/18 16:57:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# create spark session and build spark application\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('tv_shows_api_app').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f652cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _links: struct (nullable = true)\n",
      " |    |-- nextepisode: struct (nullable = true)\n",
      " |    |    |-- href: string (nullable = true)\n",
      " |    |-- previousepisode: struct (nullable = true)\n",
      " |    |    |-- href: string (nullable = true)\n",
      " |    |-- self: struct (nullable = true)\n",
      " |    |    |-- href: string (nullable = true)\n",
      " |-- averageRuntime: long (nullable = true)\n",
      " |-- dvdCountry: struct (nullable = true)\n",
      " |    |-- code: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- timezone: string (nullable = true)\n",
      " |-- ended: string (nullable = true)\n",
      " |-- externals: struct (nullable = true)\n",
      " |    |-- imdb: string (nullable = true)\n",
      " |    |-- thetvdb: long (nullable = true)\n",
      " |    |-- tvrage: long (nullable = true)\n",
      " |-- genres: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- medium: string (nullable = true)\n",
      " |    |-- original: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- network: struct (nullable = true)\n",
      " |    |-- country: struct (nullable = true)\n",
      " |    |    |-- code: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- timezone: string (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- officialSite: string (nullable = true)\n",
      " |-- officialSite: string (nullable = true)\n",
      " |-- premiered: string (nullable = true)\n",
      " |-- rating: struct (nullable = true)\n",
      " |    |-- average: double (nullable = true)\n",
      " |-- runtime: long (nullable = true)\n",
      " |-- schedule: struct (nullable = true)\n",
      " |    |-- days: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- time: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- updated: long (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- webChannel: struct (nullable = true)\n",
      " |    |-- country: struct (nullable = true)\n",
      " |    |    |-- code: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- timezone: string (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- officialSite: string (nullable = true)\n",
      " |-- weight: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read the api's json file into spark dataframe and view the schema\n",
    "\n",
    "shows_df = spark.read\\\n",
    "    .format('json')\\\n",
    "    .option('inferSchema', 'true')\\\n",
    "    .option('multiLine', 'true')\\\n",
    "    .load('data/tvshows_data.json')\n",
    "\n",
    "shows_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c079a8",
   "metadata": {},
   "source": [
    "### The data is nested with 3 levels of nesting. So, the nesting must be removed. Arrays will be de-nested by using explode() and struct data types will be cleaned by using getItem() functions. Columns will be type-casted to suitable data types and renamed where needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2653ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, ArrayType, DateType, TimestampType\n",
    "from pyspark.sql.functions import col,struct,when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ecfda83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Struct Type columns are schedule, rating, network, webChannel, dvdCountry, externals, image, and links\n",
    "# columns webChannel and dvdCountry contain all \"null\" data, So these columns shall be dropped\n",
    "\n",
    "shows_df = shows_df.drop(\"webChannel\").drop(\"dvdCountry\")\n",
    "\n",
    "# dropping column 'images'\n",
    "shows_df = shows_df.drop(\"image\")\n",
    "\n",
    "# runtime and averageRuntime is similar for most of the rows, so averageRuntime shall be dropped\n",
    "shows_df = shows_df.drop(\"averageRuntime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59889d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column: 'externals' (struct) --> new columns: 'imdb', 'tvrage', 'thetvdb'\n",
    "\n",
    "shows_df = shows_df\\\n",
    "            .withColumn('imdb_id', F.col('externals').getItem('imdb'))\\\n",
    "            .withColumn('tvrage_id', F.col('externals').getItem('tvrage').cast('int'))\\\n",
    "            .withColumn('thetvdb_id', F.col('externals').getItem('thetvdb').cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af5a4393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column: 'network' (struct) --> new columns: 'id', 'name', 'country', 'officialSite'\n",
    "\n",
    "shows_df = shows_df\\\n",
    "    .withColumn('network_id', F.col('network').getItem('id').cast('int'))\\\n",
    "    .withColumn('network_name', F.col('network').getItem('name'))\\\n",
    "    .withColumn('network_country', F.col('network').getItem('country'))\\\n",
    "    .withColumn('network_official_site', F.col('network').getItem('officialSite'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "947f01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newly made column 'network_country' is also StructType\n",
    "# network_country --> 'network_country_name', 'network_country_code', 'network_country_timezone'\n",
    "\n",
    "shows_df = shows_df\\\n",
    "    .withColumn('network_country_name', F.col('network_country').getItem('name'))\\\n",
    "    .withColumn('network_country_code', F.col('network_country').getItem('code'))\\\n",
    "    .withColumn('network_country_timezone', F.col('network_country').getItem('timezone'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59da3c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column 'schedule' (struct) --> 'airing_days', 'airing_time'\n",
    "\n",
    "shows_df = shows_df\\\n",
    "    .withColumn('airing_time', F.col('schedule').getItem('time'))\\\n",
    "    .withColumn('airing_days', F.col('schedule').getItem('days'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e0574e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column 'airing_days' (array) --> explode() --> strings\n",
    "\n",
    "shows_df = shows_df.withColumn('airing_days', F.explode('airing_days'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbf31c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column 'rating' (struct) --> 'average_rating' (renamed as 'rating')\n",
    "\n",
    "shows_df = shows_df\\\n",
    "    .withColumn('rating', F.col('rating').getItem('average').cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daade65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column '_links' (struct) --> 'next_episode_link', 'prev_episode_link', 'current_episode_link'\n",
    "\n",
    "shows_df = shows_df\\\n",
    "    .withColumn('current_episode_link', F.col('_links').getItem('self'))\\\n",
    "    .withColumn('next_episode_link', F.col('_links').getItem('nextepisode'))\\\n",
    "    .withColumn('prev_episode_link', F.col('_links').getItem('previousepisode'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fead0f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each column is of struct type, containing only one column 'href'\n",
    "\n",
    "shows_df = shows_df\\\n",
    "    .withColumn('current_episode_link', F.col('current_episode_link').getItem('href'))\\\n",
    "    .withColumn('next_episode_link', F.col('next_episode_link').getItem('href'))\\\n",
    "    .withColumn('prev_episode_link', F.col('prev_episode_link').getItem('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "988fddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column 'genres' (array) --> explode() --> strings\n",
    "\n",
    "shows_df = shows_df.withColumn('genre', F.explode('genres'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fb014f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type-casting and renaming columns:\n",
    "\n",
    "shows_df = shows_df.withColumn('premiere_date', col('premiered').cast(DateType()))\\\n",
    "    .withColumn('end_date', col('ended').cast(DateType()))\\\n",
    "    .withColumn('airing_time', col('airing_time').cast(TimestampType()))\\\n",
    "    .withColumn('id', col('id').cast(IntegerType()))\\\n",
    "    .withColumn('runtime', col('runtime').cast(IntegerType()))\\\n",
    "    .withColumn('weight', col('weight').cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29586888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only cleaned columns in the dataframe\n",
    "\n",
    "shows_df = shows_df\\\n",
    "    .select('id','url', 'name', 'type', 'language', 'genre', 'status', 'runtime', 'premiere_date',\\\n",
    "            'end_date', 'officialSite', 'airing_days', 'airing_time', 'rating', 'weight', 'network_id',\\\n",
    "            'network_name', 'network_country_name', 'network_country_code','network_country_timezone',\\\n",
    "            'network_official_site', 'imdb_id', 'tvrage_id', 'thetvdb_id', 'updated', 'summary',\\\n",
    "            'current_episode_link', 'next_episode_link', 'prev_episode_link'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41b0f754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- runtime: integer (nullable = true)\n",
      " |-- premiere_date: date (nullable = true)\n",
      " |-- end_date: date (nullable = true)\n",
      " |-- officialSite: string (nullable = true)\n",
      " |-- airing_days: string (nullable = true)\n",
      " |-- airing_time: timestamp (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      " |-- weight: integer (nullable = true)\n",
      " |-- network_id: integer (nullable = true)\n",
      " |-- network_name: string (nullable = true)\n",
      " |-- network_country_name: string (nullable = true)\n",
      " |-- network_country_code: string (nullable = true)\n",
      " |-- network_country_timezone: string (nullable = true)\n",
      " |-- network_official_site: string (nullable = true)\n",
      " |-- imdb_id: string (nullable = true)\n",
      " |-- tvrage_id: integer (nullable = true)\n",
      " |-- thetvdb_id: integer (nullable = true)\n",
      " |-- updated: long (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- current_episode_link: string (nullable = true)\n",
      " |-- next_episode_link: string (nullable = true)\n",
      " |-- prev_episode_link: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shows_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "469f48e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/18 16:58:52 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "+---+--------------------+--------------+--------+--------+---------------+------+-------+-------------+----------+--------------------+-----------+-------------------+------+------+----------+------------+--------------------+--------------------+------------------------+---------------------+---------+---------+----------+----------+--------------------+--------------------+-----------------+--------------------+\n",
      "| id|                 url|          name|    type|language|          genre|status|runtime|premiere_date|  end_date|        officialSite|airing_days|        airing_time|rating|weight|network_id|network_name|network_country_name|network_country_code|network_country_timezone|network_official_site|  imdb_id|tvrage_id|thetvdb_id|   updated|             summary|current_episode_link|next_episode_link|   prev_episode_link|\n",
      "+---+--------------------+--------------+--------+--------+---------------+------+-------+-------------+----------+--------------------+-----------+-------------------+------+------+----------+------------+--------------------+--------------------+------------------------+---------------------+---------+---------+----------+----------+--------------------+--------------------+-----------------+--------------------+\n",
      "|  1|https://www.tvmaz...|Under the Dome|Scripted| English|          Drama| Ended|     60|   2013-06-24|2015-09-10|http://www.cbs.co...|   Thursday|2022-11-18 22:00:00|   6.5|    99|         2|         CBS|       United States|                  US|        America/New_York| https://www.cbs.com/|tt1553656|    25988|    264492|1631010933|<p><b>Under the D...|https://api.tvmaz...|             null|https://api.tvmaz...|\n",
      "|  1|https://www.tvmaz...|Under the Dome|Scripted| English|Science-Fiction| Ended|     60|   2013-06-24|2015-09-10|http://www.cbs.co...|   Thursday|2022-11-18 22:00:00|   6.5|    99|         2|         CBS|       United States|                  US|        America/New_York| https://www.cbs.com/|tt1553656|    25988|    264492|1631010933|<p><b>Under the D...|https://api.tvmaz...|             null|https://api.tvmaz...|\n",
      "|  1|https://www.tvmaz...|Under the Dome|Scripted| English|       Thriller| Ended|     60|   2013-06-24|2015-09-10|http://www.cbs.co...|   Thursday|2022-11-18 22:00:00|   6.5|    99|         2|         CBS|       United States|                  US|        America/New_York| https://www.cbs.com/|tt1553656|    25988|    264492|1631010933|<p><b>Under the D...|https://api.tvmaz...|             null|https://api.tvmaz...|\n",
      "+---+--------------------+--------------+--------+--------+---------------+------+-------+-------------+----------+--------------------+-----------+-------------------+------+------+----------+------------+--------------------+--------------------+------------------------+---------------------+---------+---------+----------+----------+--------------------+--------------------+-----------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shows_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6f9f42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "582"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shows_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a131ebf0",
   "metadata": {},
   "source": [
    "# Data Transformation in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94240484",
   "metadata": {},
   "source": [
    "### Tasks:\n",
    "1. Count the number of TV shows of each genre and sort from highest to lowest.\n",
    "2. List the tv shows by type (Scripted/Reality/Animation, etc.) and status (running or ended), then give the number of shows in each list\n",
    "3. Find the average, maximum, and minimum weight of shows grouped by network name\n",
    "4. Highest rated TV show(s) of each country along with rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5f1fda",
   "metadata": {},
   "source": [
    "## 1. Count the number of TV shows of each genre and sort from highest to lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f543eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|          genre|count|\n",
      "+---------------+-----+\n",
      "|          Drama|  151|\n",
      "|         Comedy|   73|\n",
      "|          Crime|   54|\n",
      "|         Action|   53|\n",
      "|       Thriller|   38|\n",
      "|Science-Fiction|   38|\n",
      "|        Romance|   32|\n",
      "|      Adventure|   24|\n",
      "|         Horror|   21|\n",
      "|         Family|   19|\n",
      "|   Supernatural|   18|\n",
      "|        Mystery|   13|\n",
      "|        Fantasy|   12|\n",
      "|        Medical|    6|\n",
      "|          Legal|    6|\n",
      "|          Music|    5|\n",
      "|          Anime|    4|\n",
      "|            War|    4|\n",
      "|        History|    4|\n",
      "|        Western|    3|\n",
      "+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# groupby, aggregation, and sorting\n",
    "\n",
    "from pyspark.sql.functions import desc\n",
    "\n",
    "genre_shows_count = shows_df\\\n",
    "        .groupBy('genre')\\\n",
    "        .count()\\\n",
    "        .orderBy(desc('count'))\n",
    "\n",
    "genre_shows_count.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b4b215",
   "metadata": {},
   "source": [
    "## 2. List the tv shows by type (Scripted/Reality/Animation, etc.) and status (running or ended), then give the number of shows in each list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee1b75a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 11:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------------------+---------------+\n",
      "|       Type| Status|       TV Shows List|Number of Shows|\n",
      "+-----------+-------+--------------------+---------------+\n",
      "|   Scripted|  Ended|[Parks and Recrea...|            191|\n",
      "|   Scripted|Running|[Fargo, True Dete...|             16|\n",
      "|  Animation|  Ended|[Star Wars: Rebel...|              7|\n",
      "|    Reality|Running|[The Amazing Race...|              6|\n",
      "|  Animation|Running|[South Park, Amer...|              6|\n",
      "|  Talk Show|  Ended|[The Daily Show w...|              3|\n",
      "|Documentary|  Ended|       [Long Shadow]|              1|\n",
      "+-----------+-------+--------------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# window function, UDF, ordering\n",
    "\n",
    "from pyspark.sql.functions import collect_set, col\n",
    "from pyspark.sql import Window as W  \n",
    "\n",
    "# using window function\n",
    "window_spec_2 = W.partitionBy('type', 'status')\n",
    "\n",
    "# making list of tv shows by type and status\n",
    "shows_list = shows_df\\\n",
    "                    .withColumn('TV Shows List', collect_set('name').over(window_spec_2))\\\n",
    "                    .select(col('type').alias('Type'), col('status').alias('Status'), col('TV Shows List'))\\\n",
    "                    .distinct()\n",
    "\n",
    "\n",
    "# creating udf to count number of elements in a list\n",
    "list_len_udf = F.udf(lambda x: len(x), IntegerType())\n",
    "\n",
    "# adding number of shows column\n",
    "shows_list_count = shows_list\\\n",
    "                .withColumn('Number of Shows', list_len_udf(col('TV Shows List')))\\\n",
    "                .orderBy(desc(col('Number of Shows')))\n",
    "\n",
    "\n",
    "shows_list_count.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334a777c",
   "metadata": {},
   "source": [
    "## 3. Find the average, maximum, and minimum weight of shows grouped by network name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "faf63ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------+--------------+--------------+\n",
      "|  Network Name|   Average Weight|Maximum Weight|Minimum Weight|\n",
      "+--------------+-----------------+--------------+--------------+\n",
      "|           NBC|89.80952380952381|           100|            49|\n",
      "|           RTL|             88.0|            88|            88|\n",
      "|      Showtime|91.73529411764706|            98|            48|\n",
      "|           CMT|             89.0|            89|            89|\n",
      "|           ITV|             69.0|            69|            69|\n",
      "|   BBC America|             93.0|            93|            93|\n",
      "|       Cinemax|             95.6|            96|            95|\n",
      "|El Rey Network|             98.0|            98|            98|\n",
      "|Comedy Central|86.11111111111111|            99|            78|\n",
      "|   WGN America|             93.0|            93|            93|\n",
      "|     Disney XD|             98.0|            98|            98|\n",
      "|      Lifetime|            83.75|            91|            65|\n",
      "|          Syfy|93.33333333333333|            98|            88|\n",
      "|   Nickelodeon|             94.0|            94|            94|\n",
      "|           A&E|             91.6|            92|            91|\n",
      "|       BBC Two|             33.0|            33|            33|\n",
      "|   Sundance TV|             92.0|            92|            92|\n",
      "|        The CW|92.55263157894737|            99|            66|\n",
      "|           HBO|93.83870967741936|            99|            61|\n",
      "|           TF1|             84.0|            84|            84|\n",
      "+--------------+-----------------+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# summary statistics\n",
    "\n",
    "from pyspark.sql.functions import avg, min, max\n",
    "\n",
    "show_weight_by_network = shows_df\\\n",
    "    .groupBy(col(\"network_name\").alias(\"Network Name\")).agg(avg(\"weight\").alias(\"Average Weight\"),\\\n",
    "                                                            max(\"weight\").alias(\"Maximum Weight\"),\\\n",
    "                                                            min(\"weight\").alias(\"Minimum Weight\"))\\\n",
    "    .orderBy(desc(\"Average Weight\"))\\\n",
    "    .dropna().distinct()\n",
    "\n",
    "show_weight_by_network.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850e5975",
   "metadata": {},
   "source": [
    "## 4. Highest rated TV show(s) of each country along with rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69d7544a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+---------------------+\n",
      "|       Country|Rating|Highest Rated Show(s)|\n",
      "+--------------+------+---------------------+\n",
      "|        Canada|   8.6| [Vikings, Orphan ...|\n",
      "|        France|   7.9|     [Crossing Lines]|\n",
      "|       Germany|   7.2| [Transporter: The...|\n",
      "|         Japan|   8.8|         [Death Note]|\n",
      "|United Kingdom|   8.5|             [Utopia]|\n",
      "| United States|   9.2|       [Breaking Bad]|\n",
      "+--------------+------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# window function (denserank), groupBy, aggregation, collect_set\n",
    "\n",
    "window_spec_5 = W.partitionBy('network_country_name').orderBy(desc('rating'))\n",
    "\n",
    "ranked_df = shows_df.withColumn('rank', F.dense_rank().over(window_spec_5)).filter('rank == 1')\n",
    "\n",
    "max_rating_df = ranked_df.select(col('network_country_name').alias('Country'),\\\n",
    "                                 col('name'),\\\n",
    "                                 col('rating').alias('Rating')).dropna().distinct()\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import collect_set\n",
    "\n",
    "highest_rated_shows = max_rating_df\\\n",
    "    .groupBy(col('Country'), col('Rating'))\\\n",
    "    .agg(collect_set(col('name')).alias('Highest Rated Show(s)'))\n",
    "\n",
    "highest_rated_shows.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308a6198",
   "metadata": {},
   "source": [
    "## Write each transformed dataframe to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f174440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_shows_count.toPandas().to_json('output_json/q1_genre_shows_count.json', orient='records')\n",
    "shows_list_count.toPandas().to_json('output_json/q2_shows_list_count.json', orient='records')\n",
    "show_weight_by_network.toPandas().to_json('output_json/q3_shows_weight.json', orient='records')\n",
    "highest_rated_shows.toPandas().to_json('output_json/q4_highest_rated_shows.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72813501",
   "metadata": {},
   "source": [
    "### Viewing the schema of each dataframe to create schema in schemas.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6110cfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- genre: string (nullable = true)\n",
      " |-- count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genre_shows_count.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f11128af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Type: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- TV Shows List: array (nullable = false)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- Number of Shows: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shows_list_count.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a76924b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Network Name: string (nullable = true)\n",
      " |-- Average Weight: double (nullable = true)\n",
      " |-- Maximum Weight: integer (nullable = true)\n",
      " |-- Minimum Weight: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_weight_by_network.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f567f0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Rating: float (nullable = true)\n",
      " |-- Highest Rated Show(s): array (nullable = false)\n",
      " |    |-- element: string (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "highest_rated_shows.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
